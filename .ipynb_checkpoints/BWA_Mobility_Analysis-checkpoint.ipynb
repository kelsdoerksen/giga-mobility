{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9722a890",
   "metadata": {},
   "source": [
    "# Analysis of Botswana MapBox Mobility Data\n",
    "\n",
    "The purpose of this notebook is to visualize and assess the MapBox mobility data over Botswana for School and Non-School samples. The below analysis uses the hourly mobility data for October, November, December 2023.\n",
    "\n",
    "MapBox Docs: https://docs.mapbox.com/data/movement/guides\n",
    "\n",
    "The **Data Pre-Processing** section queries each school and non-school sample in the Botswana geojson cleaned schools file, and either calculates the MapBox mobility data per point that a sample (school or non-school) directly intersects with or generates a 300m buffer extent surrounding the school/non-school point and extracts the corresponding mobility data over that region. We cluster the data by either a 4-cluster system (representing North, West, East, South of the country, respectively) or Administrative Boundaries Level 1 and save the categorized data in the format of a dictionary of dataframes, saving via pickle. You can choose to go through each step of the data pre-processing to generate the dictionary of dataframes, or skip to the **Data Visualization** section to load the pickled dictionary and generate the plots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3782e32",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e155a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.stats import zscore\n",
    "import requests\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import folium\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "from functools import partial\n",
    "import pyproj\n",
    "from shapely import geometry\n",
    "from shapely.geometry import Point, Polygon, LineString\n",
    "from shapely.ops import transform\n",
    "import matplotlib.pyplot as plt\n",
    "from pyproj import Transformer, CRS\n",
    "import mercantile\n",
    "from itertools import combinations\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "import seaborn as sn\n",
    "import pickle\n",
    "import json\n",
    "import stats\n",
    "import copy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e83b17d",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8259497f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: filepaths hard-coded to Kelsey Doerksen's local machine, to update\n",
    "mobility_filepath = '/Users/kelseydoerksen/Desktop/Giga/SchoolMapping/BWA/Mobility'\n",
    "\n",
    "# Loading hourly mobility data\n",
    "hourly_movement_df = pd.read_csv('{}/weekday-weekend-1hour.csv'.format(mobility_filepath))\n",
    "\n",
    "# Loading 4-hour mobility day\n",
    "day_of_week_4hour_df = pd.read_csv('{}/day_of_week-4hour.csv'.format(mobility_filepath))\n",
    "\n",
    "# Loading BWA school geojson data\n",
    "sample_df = gpd.read_file('/Users/kelseydoerksen/Desktop/Giga/SchoolMapping/BWA/BWA_train.geojson')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9df97cb",
   "metadata": {},
   "source": [
    "## Data Pre-Processing\n",
    "We would like to aggregate and analyze the activity associated with individual school and non-school samples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e7ca92",
   "metadata": {},
   "source": [
    "### Adding Mobility Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b603c4",
   "metadata": {},
   "source": [
    "### Intersection Analysis\n",
    "We would like to spatially join the sample point layer with the MapBox mobility polygon layer, retaining the point geometries and grabbing the attributes of the intersecting polygons (i.e. the activity data)\n",
    "Two methodologies:\n",
    "1. Direct Intersection: mobility information if the target directly intersects with the available MapBox mobility data. \n",
    "2. Surrounding Buffer: mobility information for a user-defined buffer extent surrounding the target with the available MapBox mobility data. \n",
    "3. Intersection + Nearest Mobiltity porint: mobility information if the target directly intersects with available MapBox mobility data as well as for the nearest mobility data to school if there is no direct intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1593de38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polygon_from_tile(geography):\n",
    "    \"\"\"\n",
    "    Converts the mercantile quadkey to polygon\n",
    "    \n",
    "    Args:\n",
    "        df: dataframe \n",
    "    \"\"\"\n",
    "    tile = mercantile.quadkey_to_tile(str(geography))\n",
    "    return Polygon(mercantile.feature(tile)['geometry']['coordinates'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22f7bdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mobility_data_intersection(movement_df, aoi_df):\n",
    "    \"\"\"\n",
    "    Adds movement data to the school df\n",
    "    :param: movement_df: dataframe of MapBox mobility data\n",
    "    :param: aoi_df: df of aoi targets\n",
    "    \n",
    "    :return: aoi_df_with_mobility: df with added mobility data per aoi\n",
    "    \"\"\"\n",
    "    # Add mercantile tile as polygon to movement df\n",
    "    movement_df['mercantile_polygon'] = movement_df['geography'].apply(get_polygon_from_tile)\n",
    "    # Change name to geometry\n",
    "    movement_df = movement_df.rename(columns={'mercantile_polygon': 'geometry'})\n",
    "    # Transform mobility data to gpd\n",
    "    movement_gdf = gpd.GeoDataFrame(movement_df, crs=\"EPSG:4326\")\n",
    "    \n",
    "    if 'geo' in school_df.columns:\n",
    "        aoi_df = school_df.rename(columns={'geo': 'geometry'})\n",
    "        aoi_df.set_geometry(\"geometry\")\n",
    "\n",
    "    # Combine aoi samples with mobility data\n",
    "    aoi_with_mobility = aoi_df.sjoin(movement_gdf, how='left')\n",
    "\n",
    "    # Drop if aoi does not intersect with available MapBox mobility data\n",
    "    aoi_with_mobility = aoi_with_mobility.dropna(subset=[\"geography\"])\n",
    "    \n",
    "    return aoi_with_mobility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a49be210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aeqd_reproj_buffer(center, radius=300):\n",
    "    \"\"\"\n",
    "    # Generate circular boundary around targets of user-specified \n",
    "    (defaut 300m) radius.\n",
    "    Converts center coordinates to AEQD projection,\n",
    "    draws a circle of given radius around the center coordinates,\n",
    "    converts both polygons back to original ESRI:54009\n",
    "    \n",
    "    Args:\n",
    "        center center coordinates of the circle (derived from school location)\n",
    "        radius (integer): circle's radius in meters.\n",
    "    \n",
    "    Returns:\n",
    "        A shapely.geometry Polygon object for circle of given radius.\n",
    "    \"\"\"\n",
    "    lat = center.y\n",
    "    lon = center.x\n",
    "    \n",
    "    esri54009_to_epsg4326 = Transformer.from_crs(\"ESRI:54009\", \"EPSG:4326\", always_xy=True)\n",
    "    epsg4326_to_aeqd = Transformer.from_crs(\"EPSG:4326\", \"ESRI:54032\")\n",
    "    aeqd_to_epsg4326 = Transformer.from_crs(\"ESRI:54032\", \"EPSG:4326\", always_xy=False)\n",
    "\n",
    "    # Transform the center coordinates from 54009 to AEQD\n",
    "    point_epsg4326 = Point(esri54009_to_epsg4326.transform(lon, lat))\n",
    "    point_transformed = Point(epsg4326_to_aeqd.transform(point_epsg4326.x, point_epsg4326.y))\n",
    "    \n",
    "    # Get buffer of defined radius\n",
    "    buffer = point_transformed.buffer(radius)\n",
    "    \n",
    "    # Get the polygon with lat lon coordinates\n",
    "    circle_poly = transform(aeqd_to_epsg4326.transform, buffer)\n",
    "    \n",
    "    return circle_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e6bc643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of the mapbox data that is overlapping the radius extent we specified\n",
    "def generate_quadkeys(circle_poly, zoom):\n",
    "    \"\"\"\n",
    "    Generate a list of quadkeys that overlap our circles\n",
    "    Args:\n",
    "        circle_poly (shapely.geometry Polygon): circle polygon object drawn \n",
    "            around a school/non-school\n",
    "        zoom (integer): zoom level.\n",
    "        \n",
    "    Return:\n",
    "        List of quadkeys as string\n",
    "    \"\"\"\n",
    "    return [mercantile.quadkey(x) for x in mercantile.tiles(*circle_poly.bounds, zoom)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58853c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_movement_data_buffer(sample_df, mobility_df):\n",
    "    \"\"\"\n",
    "    Adding mobility data based on quadkey intersections for buffer analysis\n",
    "    \"\"\"\n",
    "    full_data = []\n",
    "    for i in range(len(sample_df)):\n",
    "        data_list = []\n",
    "        for z18_quadkey in sample_df.loc[i][\"z18_quadkeys\"]:\n",
    "            data_list.append(mobility_df[mobility_df[\"geography\"] == int(z18_quadkey)])\n",
    "        data_df = pd.concat(data_list)\n",
    "        data_df['UID'] = sample_df.loc[i]['UID']\n",
    "        data_df['name'] = sample_df.loc[i]['name']\n",
    "        full_data.append(data_df)\n",
    "    \n",
    "    if full_data:\n",
    "        full_df = pd.concat(full_data)\n",
    "        return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53b22486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_movement_data(query_df, movement_df, month_subset, intersection_buffer):\n",
    "    \"\"\"\n",
    "    Add movement data if MapBox quadkey exists\n",
    "    Args:\n",
    "        query_df: dataframe of aoi samples\n",
    "        movement_df: MapBox mobility data df\n",
    "        month_subset: month of movement data to query\n",
    "        intersection_buffer: buffer extent for intersection of mobility data surrounding aoi\n",
    "        \n",
    "    Return:\n",
    "        df with movement data\n",
    "    \"\"\"\n",
    "    date_dict = {\n",
    "        'oct': '2023-10-01',\n",
    "        'nov': '2023-11-01',\n",
    "        'dec': '2023-12-01'\n",
    "    }\n",
    "    print('Running for date subset: {}'.format(month_subset))\n",
    "    \n",
    "    # Make a copy of the df so we can filter things\n",
    "    movement_df_copy = movement_df.copy(deep=True)\n",
    "    \n",
    "    # Subset movement dict to the time we are interested in\n",
    "    if not month_subset == 'all':\n",
    "        movement_df_copy = movement_df_copy[movement_df[\"start_date\"] == date_dict['{}'.format(month_subset)]]\n",
    "    \n",
    "    if intersection_buffer == 0:\n",
    "        samples_with_mobility = add_mobility_data_intersection(movement_df_copy, query_df)\n",
    "        if not month_subset == 'all':\n",
    "            samples_with_mobility_date_subset = samples_with_mobility[samples_with_mobility[\"start_date\"] == date_dict['{}'.format(month_subset)]]\n",
    "        else:\n",
    "            return samples_with_mobility\n",
    "    else:\n",
    "        # Run for buffer\n",
    "        samples_with_mobility_date_subset = add_movement_data_buffer(query_df, movement_df_copy)\n",
    "    \n",
    "    return samples_with_mobility_date_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9082ce35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_hourly_stat_ai(df, time_period, target, stat):\n",
    "    \"\"\"\n",
    "    Aggregate movement data to hourly sum based on \n",
    "    quadkeys that interset with user-defined buffer\n",
    "    and calculate the hourly average ai over \n",
    "    the time period for all of the samples\n",
    "    :param: df: dataframe of aoi + mobility data to aggregate\n",
    "    :time_period: weekday (0) or weekend(1) MapBox data\n",
    "    :param: target: refers to the target we want to get stat for, ie activity_index_total, or some normalized version\n",
    "    :param: stat: stat to calculate, mean or median\n",
    "    \"\"\"\n",
    "    if pd.DataFrame(df) is None:\n",
    "        return\n",
    "    grouped = df.groupby(['UID', 'agg_day_period', 'agg_time_period', 'start_date', 'end_date'])\n",
    "    sum_data = grouped[target].sum()\n",
    "    sum_df = sum_data.reset_index()\n",
    "    \n",
    "    \n",
    "    hourly_df = sum_df[sum_df['agg_day_period'] == int(time_period)]\n",
    "    UIDS = hourly_df['UID'].unique().tolist()\n",
    "    data_list =[]\n",
    "    for uid in UIDS:\n",
    "        hourly_df_uid = hourly_df[hourly_df['UID'] == uid]\n",
    "        time_periods = hourly_df_uid['agg_time_period'].unique().tolist()\n",
    "        df_list = []\n",
    "        for t in time_periods:\n",
    "            df_new = pd.DataFrame()\n",
    "            subset_df = hourly_df_uid[hourly_df_uid['agg_time_period'] == t]\n",
    "            sum_ai = subset_df[target].sum()\n",
    "            df_new['agg_time_period'] = [t]\n",
    "            df_new[target] = [sum_ai]\n",
    "            df_new['UID'] = [uid]\n",
    "            df_list.append(df_new)\n",
    "        df_combined = pd.concat(df_list)\n",
    "        data_list.append(df_combined)\n",
    "    \n",
    "    if len(data_list) < 0:\n",
    "        return None\n",
    "    df_final= pd.concat(data_list)\n",
    "    if stat == 'mean':\n",
    "        stat_hourly_data = hourly_df.groupby(['agg_time_period'])[target].mean()\n",
    "    if stat == 'median':\n",
    "        stat_hourly_data = hourly_df.groupby(['agg_time_period'])[target].mean()\n",
    "    \n",
    "    return stat_hourly_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f95219",
   "metadata": {},
   "source": [
    "## Clustering based on Location\n",
    "From MapBox: The data for each country is normalized within that country. Comparisons made over short timescales and short distances are more trustworthy than those made over long timescales and distances. Comparisons made over areas that have a high average activity are more trustworthy than those made over areas that have low average activity.\n",
    "\n",
    "Several clustering methods are shown below; K-Means, Admin Boundary Level2, and Admin Boundary Level1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f084ddab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get school data as coords\n",
    "coords = []\n",
    "for i in range(len(school_df)):\n",
    "    coords.append([school_df.loc[i].geometry.x, school_df.loc[i].geometry.y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb0fbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using elbow method to determine number of clusters we should use\n",
    "wcss = []\n",
    "for i in range(1, 14):\n",
    "    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42, n_init=10)\n",
    "    kmeans.fit(coords)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "plt.plot(range(1, 14), wcss)\n",
    "plt.title('The Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb9151d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cluster_id(df, n_clusters):\n",
    "    \"\"\"\n",
    "    Add cluster id to dataframe\n",
    "    \"\"\"\n",
    "    # From plot, we see 4 is the optimal cluster number\n",
    "    kmeans = KMeans(n_clusters = 4, init = 'k-means++', random_state = 5,  max_iter=400, n_init=10)\n",
    "    y_kmeans = kmeans.fit_predict(coords)\n",
    "    k=pd.DataFrame(y_kmeans, columns=['cluster'])\n",
    "    \n",
    "    # add cluster class to school dataframe\n",
    "    df_with_cluster = df.join(k)\n",
    "    \n",
    "    return df_with_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7683d5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cluster id to dataframe\n",
    "school_df_with_clusters = add_cluster_id(school_df, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19edd94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_label0 = school_df_with_clusters[school_df_with_clusters['cluster'] == 0]\n",
    "filtered_label1 = school_df_with_clusters[school_df_with_clusters['cluster'] == 1]\n",
    "filtered_label2 = school_df_with_clusters[school_df_with_clusters['cluster'] == 2]\n",
    "filtered_label3 = school_df_with_clusters[school_df_with_clusters['cluster'] == 3]\n",
    "\n",
    "plt.scatter(filtered_label0.geometry.x, filtered_label0.geometry.y, label='Cluster 0')\n",
    "plt.scatter(filtered_label1.geometry.x, filtered_label1.geometry.y, label='Cluster 1')\n",
    "plt.scatter(filtered_label2.geometry.x, filtered_label2.geometry.y, label='Cluster 2')\n",
    "plt.scatter(filtered_label3.geometry.x, filtered_label3.geometry.y, label='Cluster 3')\n",
    "plt.legend()\n",
    "plt.title('K-Means Clustered School and Non-school samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22a9244",
   "metadata": {},
   "source": [
    "## Clustering via administrative boundaries\n",
    "We can also cluster via administrative boundaries, let's do this and see how many clusters we get, combining very small clusters together as MapBox notes that this is an ineffective way to analyze data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98075c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_via_adm(sample_df, adm_level):\n",
    "    \"\"\"\n",
    "    Function to cluster data via ADM boundaries\n",
    "    :param: sample_df: df of school and non-school samples to cluster\n",
    "    :param: adm_level: administrative level to query for generating clusters\n",
    "    \"\"\"\n",
    "    # Load country admin levels\n",
    "    country_adm_levels = gpd.read_file('/Users/kelseydoerksen/Desktop/Giga/SchoolMapping/BWA/geoBoundaries-BWA-ADM{}.geojson'.format(adm_level))\n",
    "    \n",
    "    # Transform sample df to EPSG4326\n",
    "    sample_df_epsg4326 = sample_df.to_crs('EPSG:4326')\n",
    "    \n",
    "    # Get intersection of sample df with admin boundaries\n",
    "    sample_df_with_intersections = gpd.overlay(sample_df_epsg4326, country_adm_levels, how='intersection')\n",
    "    \n",
    "    # Plot clusters to observe\n",
    "    clusters = sample_df_with_intersections ['shapeName'].unique()\n",
    "    plt. figure(figsize=(8, 6))\n",
    "    for i in range(len(clusters)):\n",
    "        filt = sample_df_with_intersections [sample_df_with_intersections ['shapeName'] == clusters[i]]\n",
    "        plt.scatter(filt.geometry.x, filt.geometry.y, label=clusters[i])\n",
    "\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.title('Botswana ADM{} Boundary School/Non-School Sample Clustering'.format(adm_level))\n",
    "    plt.show()\n",
    "    \n",
    "    return sample_df_with_intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b80169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering based on ADM2\n",
    "school_df_with_clusters_adm2 = cluster_via_adm(school_df, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4d9102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering based on ADM1\n",
    "school_df_with_clusters = cluster_via_adm(school_df, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a34fa65",
   "metadata": {},
   "source": [
    "Looking at above clustering methods, clustering via adminstrative boundaries level 2 may result in too small of sample sizes, which will result in our Mobility analysis not being meaningful. **We will proceed with Admin Boundaries 1 clustering**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b186a44d",
   "metadata": {},
   "source": [
    "# Intersection and Nearest Mobility Point Analysis\n",
    "This analysis is to add mobility data for each of the samples based on the nearest mobility data to aoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cf591db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mobility_aoi_nearest(mobility_df, aoi_df):\n",
    "    \"\"\"\n",
    "    Add the mobility data point for closest data to aoi\n",
    "    :param: mobility_df: dataframe of mobility data\n",
    "    :param: aoi_df: df of samples\n",
    "    \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    # Making some copies of the mobility, aoi df so we can manipulate without impacting original\n",
    "    mobility_df = mobility_df.copy(deep=True)\n",
    "    aoi_gpd = aoi_df.copy(deep=True)\n",
    "    \n",
    "    # Add mercantile information to mobility gpd so we can get polygon\n",
    "    mobility_df['mercantile_polygon'] = hourly_movement_df['geography'].apply(get_polygon_from_tile)\n",
    "    mobility_df = mobility_df.rename(columns={'mercantile_polygon': 'geometry'})\n",
    "    mobility_gpd = gpd.GeoDataFrame(mobility_df, crs='EPSG:4326')\n",
    "    \n",
    "    \n",
    "    # Update CRS so that we can calculate nearest point\n",
    "    aoi_gpd = aoi_gpd.to_crs('EPSG:3857')\n",
    "    mobility_gpd = mobility_gpd.to_crs('EPSG:3857')\n",
    "\n",
    "    combo_df = gpd.sjoin_nearest(mobility_gpd, aoi_gpd, how='left', distance_col = 'dist_to_mobility')\n",
    "    \n",
    "    # Get T/F mobility intersection as 0/1 for filtering and to teach model as feature\n",
    "    intersected = combo_df['dist_to_mobility'] == 0\n",
    "    combo_df['intersecting_mobility'] = intersected.astype(int)\n",
    "    \n",
    "    return combo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3af26383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mobility_timeseries_feature(aoi_samples_df, sample_id, day_period, month, stat):\n",
    "    \"\"\"\n",
    "    Calculate mobility time series features for samples\n",
    "    :param: aoi_samples_df: df of samples to filter and process\n",
    "    :param: sample_id: id of sample we are querying (school/non-school)\n",
    "    :param: day_period: refers to agg_time_period from mobility data (weekday or weekend)\n",
    "    :param: month: refers to month for which we want to query data for\n",
    "    :param: stat: refers to stat to return\n",
    "    \"\"\"\n",
    "    \n",
    "    month_dict = {\n",
    "        'oct': '2023-10-01',\n",
    "        'nov': '2023-11-01',\n",
    "        'dec': '2023-12-01'\n",
    "    }\n",
    "    \n",
    "    mask = (aoi_samples_df['UID'] == sample_id) & (aoi_samples_df['agg_day_period'] == day_period) & (aoi_samples_df['start_date'] == month_dict[month])\n",
    "    filtered_df = aoi_samples_df[mask]\n",
    "    \n",
    "    if len(filtered_df) == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    # Calculate features\n",
    "    if stat == 'var':\n",
    "        return filtered_df['activity_index_total'].var()\n",
    "    if stat == 'peak_activity':\n",
    "        filtered_df = filtered_df.sort_values(by='agg_time_period')\n",
    "        peak_activity_time = filtered_df.loc[filtered_df['activity_index_total'].idxmax()]['agg_time_period']\n",
    "        return peak_activity_time\n",
    "    if stat == 'measurement_count':\n",
    "        return len(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcd91a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series dictionary to extract features from mobility, hard-coding november as test\n",
    "mobile_timeseries_dict_nov = {\n",
    "    'uid': [],\n",
    "    'weekend_var': [],\n",
    "    'weekend_peak_hour': [],\n",
    "    'weekend_measurement_count': [],\n",
    "    'weekday_var': [], \n",
    "    'weekday_peak_hour': [],\n",
    "    'weekday_measurement_count': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ce0de6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding mobility data and intersection/distance information\n",
    "samples_and_mobility = mobility_aoi_nearest(hourly_movement_df, sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3cd23935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geography</th>\n",
       "      <th>xlon</th>\n",
       "      <th>xlat</th>\n",
       "      <th>bounds</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>agg_day_period</th>\n",
       "      <th>agg_time_period</th>\n",
       "      <th>activity_index_total</th>\n",
       "      <th>geometry</th>\n",
       "      <th>...</th>\n",
       "      <th>name</th>\n",
       "      <th>giga_id_school</th>\n",
       "      <th>clean</th>\n",
       "      <th>validated</th>\n",
       "      <th>class</th>\n",
       "      <th>ghsl_smod</th>\n",
       "      <th>rurban</th>\n",
       "      <th>dataset</th>\n",
       "      <th>dist_to_mobility</th>\n",
       "      <th>intersecting_mobility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>780561</th>\n",
       "      <td>300300300220100200</td>\n",
       "      <td>25.357132</td>\n",
       "      <td>-25.011573</td>\n",
       "      <td>[25.3564453125, -25.012195317781785, 25.357818...</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.034161</td>\n",
       "      <td>POLYGON ((2822666.581 -2877242.619, 2822666.58...</td>\n",
       "      <td>...</td>\n",
       "      <td>Afri-Car Body &amp; General Works</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non_school</td>\n",
       "      <td>30</td>\n",
       "      <td>urban</td>\n",
       "      <td>test</td>\n",
       "      <td>255.902637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 geography       xlon       xlat  \\\n",
       "780561  300300300220100200  25.357132 -25.011573   \n",
       "\n",
       "                                                   bounds  start_date  \\\n",
       "780561  [25.3564453125, -25.012195317781785, 25.357818...  2023-12-01   \n",
       "\n",
       "          end_date  agg_day_period  agg_time_period  activity_index_total  \\\n",
       "780561  2023-12-31               0                6              0.034161   \n",
       "\n",
       "                                                 geometry  ...  \\\n",
       "780561  POLYGON ((2822666.581 -2877242.619, 2822666.58...  ...   \n",
       "\n",
       "                                 name giga_id_school clean validated  \\\n",
       "780561  Afri-Car Body & General Works           None     0       NaN   \n",
       "\n",
       "             class ghsl_smod rurban dataset dist_to_mobility  \\\n",
       "780561  non_school        30  urban    test       255.902637   \n",
       "\n",
       "        intersecting_mobility  \n",
       "780561                      0  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_and_mobility[samples_and_mobility['UID'] == 'OVERTURE-BWA-NON_SCHOOL-00000555']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c6a9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of unique uids\n",
    "uids = samples_and_mobility['UID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c46ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through and add the relevant features to the dict we want\n",
    "for u in uids:\n",
    "    print('Running for uid: {}'.format(u))\n",
    "    mobile_timeseries_dict_nov['uid'].append(u)\n",
    "    mobile_timeseries_dict_nov['weekend_var'].append(generate_mobility_timeseries_feature(samples_and_mobility, u, 1, 'nov', 'var'))\n",
    "    mobile_timeseries_dict_nov['weekend_peak_hour'].append(generate_mobility_timeseries_feature(samples_and_mobility, u, 1, 'nov', 'peak_activity'))\n",
    "    mobile_timeseries_dict_nov['weekend_measurement_count'].append(generate_mobility_timeseries_feature(samples_and_mobility, u, 1, 'nov', 'measurement_count'))\n",
    "    mobile_timeseries_dict_nov['weekday_var'].append(generate_mobility_timeseries_feature(samples_and_mobility, u, 0, 'nov', 'var'))\n",
    "    mobile_timeseries_dict_nov['weekday_peak_hour'].append(generate_mobility_timeseries_feature(samples_and_mobility, u, 0, 'nov', 'peak_activity'))\n",
    "    mobile_timeseries_dict_nov['weekday_measurement_count'].append(generate_mobility_timeseries_feature(samples_and_mobility, u, 0, 'nov', 'measurement_count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a89d770",
   "metadata": {},
   "outputs": [],
   "source": [
    "month = 'nov'\n",
    "pickle.dump(mobile_timeseries_dict_nov, open( \"/Users/kelseydoerksen/Desktop/Giga/SchoolMapping/BWA/Mobility/dict_of_mobility_features_{}.p\".format(month), \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9402cc6c",
   "metadata": {},
   "source": [
    "### School and Non-School Sample Selection\n",
    "For initial demo, 3 schools and non-schools are selected randomly via QGIS manual inspection in rural and urban areas based on the definition in the BWA_train.gejson file. \n",
    "\n",
    "Non-Schools are selected by finding a close non-school point to a school point.\n",
    "\n",
    "The definitions of each type of non-school are from their UID is:\n",
    "\n",
    "Urban:\n",
    "- OSM-BWA-NON_SCHOOL-00000835: Cloud Networks Business Center\n",
    "- OSM-BWA-NON_SCHOOL-00000849: Mmopane Police\n",
    "- OVERTURE-BWA-NON_SCHOOL-00000420: Mbizi Guest House Sebina\n",
    "\n",
    "Rural: \n",
    "- OSM-BWA-NON_SCHOOL-00000813: Bokspits Clinic\n",
    "- OSM-BWA-NON_SCHOOL-00000561: Sanitary Checkpoint\n",
    "- OSM-BWA-NON_SCHOOL-00000027: Game Scouts - Park Entry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a6bf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you would like to only run on a small subset of the schools\n",
    "\n",
    "# Subsetting data into rural-school, rural-nonschool, urban-school, urban-nonschool\n",
    "# Samples selected based on visiual inspection in QGIS \n",
    "'''\n",
    "urban_schools_subset = ['OSM-BWA-SCHOOL-00000103', 'OSM-BWA-SCHOOL-00000152', 'UNICEF-BWA-SCHOOL-00000048']\n",
    "rural_schools_subset = ['UNICEF-BWA-SCHOOL-00000335', 'UNICEF-BWA-SCHOOL-00000683', 'UNICEF-BWA-SCHOOL-00000096']\n",
    "urban_non_schools_subset = ['OSM-BWA-NON_SCHOOL-00000835', 'OSM-BWA-NON_SCHOOL-00000849', 'OVERTURE-BWA-NON_SCHOOL-00000420']\n",
    "rural_non_schools_subset = ['OSM-BWA-NON_SCHOOL-00000813', 'OSM-BWA-NON_SCHOOL-00000561', 'OSM-BWA-NON_SCHOOL-00000027']\n",
    "\n",
    "rural_school_df = school_df.copy(deep=True)[school_df['UID'].isin(rural_schools)]\n",
    "urban_school_df = school_df.copy(deep=True)[school_df['UID'].isin(urban_schools)]\n",
    "rural_nonschool_df = school_df.copy(deep=True)[school_df['UID'].isin(rural_non_schools)]\n",
    "urban_nonschool_df = school_df.copy(deep=True)[school_df['UID'].isin(urban_non_schools)]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeb85a3",
   "metadata": {},
   "source": [
    "## Dictionary Functions\n",
    "Below functions are used to generate the cluster dictionary based on the defined categories for schools and non-schools for subsetting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e79f12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cluster_dict(cluster_name, df, timeperiod):\n",
    "    \"\"\"\n",
    "    Creates a dictionary of relevant dfs per cluster\n",
    "    :param: cluster_name: cluster id\n",
    "    :param: df: dataframe of samples\n",
    "    :param: timeperiod: time period of analysis, weekday or weekend\n",
    "    \n",
    "    :return: dictionary of dataframes for the cluster\n",
    "    \"\"\"\n",
    "    school_df = df[df['class'] == 'school']\n",
    "    nonschool_df = df[df['class'] == 'non_school']\n",
    "    \n",
    "    if timeperiod == 'weekday':\n",
    "        school_df = school_df[school_df['agg_day_period'] == 0]\n",
    "        nonschool_df = nonschool_df[nonschool_df['agg_day_period'] == 0]\n",
    "    if timeperiod == 'weekend':\n",
    "        school_df = school_df[school_df['agg_day_period'] == 1]\n",
    "        nonschool_df = nonschool_df[nonschool_df['agg_day_period'] == 1]\n",
    "    \n",
    "    cluster_dict = {}\n",
    "    cluster_dict['schools_{}_ai'.format(timeperiod)] = school_df[school_df['cluster'] == cluster_name].reset_index().drop(columns=['index'])\n",
    "    cluster_dict['nonschools_{}_ai'.format(timeperiod)] = nonschool_df[nonschool_df['cluster'] == cluster_name].reset_index().drop(columns=['index'])\n",
    "    \n",
    "    # Defining building types for non-schools (to update to not have to make case sensitive)\n",
    "    clinics = ['clinic', 'hospital', 'health', 'medical', 'Clinic', 'Hospital', 'Health', 'Medical']\n",
    "    police = ['police', 'Police']\n",
    "    farm = ['farm', 'Farm']\n",
    "    \n",
    "    # Dropping samples with no names for nonschools as we can't identify these by category\n",
    "    nonschools_no_nan = nonschool_df.dropna(subset=['name'])\n",
    "    \n",
    "    # Adding filtered non-schools for cluster to dictionary\n",
    "    cluster_dict['clinics_{}_ai'.format(timeperiod)] = filter_df(nonschools_no_nan, clinics)\n",
    "    cluster_dict['police_{}_ai'.format(timeperiod)] = filter_df(nonschools_no_nan, police)\n",
    "    cluster_dict['farms_{}_ai'.format(timeperiod)] = filter_df(nonschools_no_nan, farm)\n",
    "    \n",
    "    # Subset for urban and rural schools\n",
    "    cluster_dict['urban_schools_{}_ai'.format(timeperiod)] = school_df[school_df['rurban'] == 'urban'].reset_index().drop(columns=['index'])\n",
    "    cluster_dict['rural_schools_{}_ai'.format(timeperiod)] = school_df[school_df['rurban'] == 'rural'].reset_index().drop(columns=['index'])\n",
    "    \n",
    "    # Subset for urban and rural nonschools\n",
    "    cluster_dict['urban_nonschools_{}_ai'.format(timeperiod)] = nonschool_df[nonschool_df['rurban'] == 'urban'].reset_index().drop(columns=['index'])\n",
    "    cluster_dict['rural_nonschools_{}_ai'.format(timeperiod)] = nonschool_df[nonschool_df['rurban'] == 'rural'].reset_index().drop(columns=['index'])\n",
    "    \n",
    "    return cluster_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a35726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through dataframes per cluster and add movement data, then normalize\n",
    "# Old function\n",
    "def generate_hourly_movement_per_cluster(cluster_dict, cluster_id, intersection):\n",
    "    \"\"\"\n",
    "    Generate a dictionary for cluster specified of \n",
    "    normalized hourly movement data\n",
    "    :param: cluster_dict: dictionary of dataframes per cluster\n",
    "    :param: cluster_id: cluster id\n",
    "    :param: intersection: integer representing buffer extent, if 0, represents direct intersection\n",
    "    :return: dictionary of hourly weekday and weekend mobility data\n",
    "    \"\"\"\n",
    "    mobility_cluster_dict = {'oct': None, 'nov': None, 'dec': None, 'all': None}\n",
    "    dates = ['oct', 'nov', 'dec', 'all']\n",
    "    for date in dates:\n",
    "        date_dict = {}\n",
    "        for key in cluster_dict.keys():\n",
    "            df = cluster_dict[key]\n",
    "            print('Running for key: {}'.format(key))\n",
    "            df_with_movement = add_movement_data(df, hourly_movement_df, date, intersection)\n",
    "            movement_hourly_weekday = calc_hourly_average_ai(df_with_movement, 0)\n",
    "            movement_hourly_weekend = calc_hourly_average_ai(df_with_movement, 1)\n",
    "            \n",
    "            # normalize so we can cross-compare regions\n",
    "            if movement_hourly_weekday is not None:\n",
    "                movement_hourly_weekday_norm = max_min_normalize(movement_hourly_weekday)\n",
    "            else:\n",
    "                movement_hourly_weekday_norm = None\n",
    "            if movement_hourly_weekend is not None:\n",
    "                movement_hourly_weekend_norm = max_min_normalize(movement_hourly_weekend)\n",
    "            else:\n",
    "                movement_hourly_weekend_norm = None\n",
    "            \n",
    "            date_dict['{}_hourly_weekday_ai'.format(key)] = movement_hourly_weekday_norm\n",
    "            date_dict['{}_hourly_weekend_ai'.format(key)] = movement_hourly_weekend_norm\n",
    "        mobility_cluster_dict[date] = date_dict\n",
    "    \n",
    "    return mobility_cluster_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cf4d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through dataframes per cluster and add movement data\n",
    "# Old function\n",
    "def add_movement_per_cluster(cluster_dict, cluster_id, intersection):\n",
    "    \"\"\"\n",
    "    Generate dictionary of movement data\n",
    "    :param: cluster_dict: dictionary of dataframes per cluster\n",
    "    :param: cluster_id: cluster id\n",
    "    :param: intersection: integer representing buffer extent, if 0, represents direct intersection\n",
    "    :return: dictionary of hourly weekday and weekend mobility data\n",
    "    \"\"\"\n",
    "    mobility_cluster_dict = {'oct': None, 'nov': None, 'dec': None, 'all': None}\n",
    "    dates = ['oct', 'nov', 'dec', 'all']\n",
    "    for date in dates:\n",
    "        date_dict = {}\n",
    "        for key in cluster_dict.keys():\n",
    "            df = cluster_dict[key]\n",
    "            print('Running for key: {}'.format(key))\n",
    "            df_with_movement = add_movement_data(df, hourly_movement_df, date, intersection)\n",
    "            df_with_movement_weekday = df_with_movement[df_with_movement['agg_day_period'] == 0]\n",
    "            df_with_movement_weekend = df_with_movement[df_with_movement['agg_day_period'] == 1]\n",
    "            \n",
    "            date_dict['{}_weekday_ai'.format(key)] = df_with_movement_weekday\n",
    "            date_dict['{}_weekend_ai'.format(key)] = df_with_movement_weekend\n",
    "        mobility_cluster_dict[date] = date_dict\n",
    "    \n",
    "    return mobility_cluster_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa611c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(df, filter_list):\n",
    "    \"\"\"\n",
    "    Filter df based on filtering list criteria\n",
    "    \"\"\"\n",
    "    df_list = []\n",
    "    for criteria in filter_list:\n",
    "        filt_df = df[df['name'].str.contains(criteria)]\n",
    "        filt_df = filt_df.rename(columns={\"geometry\": \"geo\"})\n",
    "        df_list.append(filt_df)\n",
    "    \n",
    "    combined_df = pd.concat(df_list, axis=0, ignore_index=True)\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7096b4d",
   "metadata": {},
   "source": [
    "## Plotting Function(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1a4f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting function\n",
    "def plot_activity_index(df, cluster_name, category, time, month):\n",
    "    \"\"\"\n",
    "    Function to plot activity index. \n",
    "    Call plt.show() after function\n",
    "    :param df: dataframe of activity data\n",
    "    :param cluster_name: name of cluster \n",
    "    :param category: category of df, i.e school, non-school, clinic, etc.\n",
    "    :param time: weekday or weekend\n",
    "    :param month: month of analysis\n",
    "    \"\"\"\n",
    "    month_dict = {\n",
    "        'oct': 'October',\n",
    "        'nov': 'November',\n",
    "        'dec': 'December'\n",
    "    }\n",
    "    plt.plot(df.index, df['activity_index_total'], label='{}'.format(time))\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize='x-small')\n",
    "    plt.xlim(0,23)\n",
    "    plt.ylim(0,1)\n",
    "    plt.xlabel('Hour of Day')\n",
    "    plt.ylabel('Activity Index')\n",
    "    plt.title('{} {} Activity Index'.format(month_dict[month], cluster_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0ec6cd",
   "metadata": {},
   "source": [
    "# Intersection Analysis 4 Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11d5b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cluster id to samples\n",
    "sample_df_with_clusters = add_cluster_id(sample_df, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2c4dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add mobility data based on intersection\n",
    "# Change crs to EPSG 4326\n",
    "sample_df_with_clusters = sample_df_with_clusters.to_crs('EPSG:4326')\n",
    "\n",
    "mobility_dict = {}\n",
    "months = ['oct','nov','dec','all']\n",
    "for month in months:\n",
    "    mobility_dict[month] = add_movement_data(sample_df_with_clusters, hourly_movement_df, month, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ad3818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-score standardization on all samples\n",
    "for m in mobility_dict.keys():\n",
    "    mobility_dict[m]['z_activity_index_total'] = (mobility_dict[m]['activity_index_total'] - mobility_dict[m]['activity_index_total'].mean()) / mobility_dict[m]['activity_index_total'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3c77c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_names = sample_df_with_clusters['cluster'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd9c1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run data dict generation\n",
    "data_dict = {}\n",
    "month_dict = {}\n",
    "months = ['oct','nov','dec','all']\n",
    "for month in months:\n",
    "    for name in cluster_names:\n",
    "        weekday = generate_cluster_dict(name, mobility_dict[month], 'weekday')\n",
    "        weekend = generate_cluster_dict(name, mobility_dict[month], 'weekend')\n",
    "        weekday.update(weekend)\n",
    "        data_dict[name] = weekday\n",
    "    pickle.dump(data_dict, open( \"/Users/kelseydoerksen/Desktop/Giga/SchoolMapping/BWA/Mobility/dict_of_unfiltered_mobility_dfs_4clusters_{}.p\".format(month), \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e9946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the months and then load data, then make the aggregation and save\n",
    "dates = ['oct', 'nov', 'dec', 'all']\n",
    "for d in dates:\n",
    "    data = pickle.load(open('/Users/kelseydoerksen/Desktop/Giga/SchoolMapping/BWA/Mobility/dict_of_unfiltered_mobility_dfs_4clusters_{}_zcore_norm.p'.format(d), 'rb'))\n",
    "    data_copy = copy.deepcopy(data)\n",
    "    weekday_keys = ['schools_weekday_ai', 'nonschools_weekday_ai', 'clinics_weekday_ai', 'police_weekday_ai', 'farms_weekday_ai', 'urban_schools_weekday_ai', 'rural_schools_weekday_ai', 'urban_nonschools_weekday_ai', 'rural_nonschools_weekday_ai']\n",
    "    weekend_keys = ['schools_weekend_ai', 'nonschools_weekend_ai', 'clinics_weekend_ai', 'police_weekend_ai', 'farms_weekend_ai', 'urban_schools_weekend_ai', 'rural_schools_weekend_ai', 'urban_nonschools_weekend_ai', 'rural_nonschools_weekend_ai']\n",
    "\n",
    "    for cluster_id in data_copy.keys():\n",
    "        for wdkey in weekday_keys:\n",
    "            data_copy[cluster_id][wdkey] = calc_hourly_average_ai(data_copy[cluster_id][wdkey], 0, 'activity_index_total')\n",
    "        for wekey in weekend_keys:\n",
    "            data_copy[cluster_id][wekey] = calc_hourly_average_ai(data_copy[cluster_id][wekey], 1, 'activity_index_total')\n",
    "    \n",
    "    # Pickle the aggregated data\n",
    "    pickle.dump(data_copy, open(\"/Users/kelseydoerksen/Desktop/Giga/SchoolMapping/BWA/Mobility/dict_of_agg_mobility_dfs_4clusters_{}.p\".format(month), \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b634aab5",
   "metadata": {},
   "source": [
    "#### Old method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd2f6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- OLD METHOD ----\n",
    "\n",
    "# Subset into school and nonschool\n",
    "school_samples_df = school_df_with_clusters.copy(deep=True)[school_df_with_clusters['class'] == 'school']\n",
    "nonschool_samples_df = school_df_with_clusters.copy(deep=True)[school_df_with_clusters['class'] == 'non_school']\n",
    "\n",
    "school_samples_df = school_samples_df.rename(columns={'cluster': 'shapeName'})\n",
    "nonschool_samples_df = nonschool_samples_df.rename(columns={'cluster': 'shapeName'})\n",
    "school_df_with_clusters = school_df_with_clusters.rename(columns={'cluster': 'shapeName'})\n",
    "\n",
    "school_df_with_clusters = school_df_with_clusters.to_crs('EPSG:4326')\n",
    "school_samples_df = school_samples_df.to_crs('EPSG:4326')\n",
    "nonschool_samples_df = nonschool_samples_df.to_crs('EPSG:4326')\n",
    "\n",
    "# Create cluster dictionaries\n",
    "cluster_names = school_df_with_clusters['shapeName'].unique()\n",
    "data_dict = {}\n",
    "for name in cluster_names:\n",
    "    data_dict['{}'.format(name)] = generate_cluster_dict(name, school_samples_df, nonschool_samples_df)\n",
    "    \n",
    "pickle.dump(data_dict, open( \"/Users/kelseydoerksen/Desktop/Giga/SchoolMapping/dict_of_unfiltered_mobility_dfs_4clusters.p\", \"wb\" ))\n",
    "# Generate mobility clusters\n",
    "data_mobility_dict = {}\n",
    "for key in data_dict.keys():\n",
    "    print('Running for key: {}'.format(key))\n",
    "    data_mobility_dict['{}'.format(key)] = generate_hourly_movement_per_cluster(data_dict[key], key, 0)\n",
    "\n",
    "# Save so we don't need to re-run a bunch of times\n",
    "pickle.dump(data_mobility_dict, open( \"/Users/kelseydoerksen/Desktop/Giga/SchoolMapping/dict_of_mobility_dfs_4clusters.p\", \"wb\" ))\n",
    "\n",
    "# Generating mobility clusters without aggregation to down-select several samples\n",
    "# Generate mobility clusters\n",
    "data_mobility_dict_no_agg = {}\n",
    "for key in data_dict.keys():\n",
    "    print('Running for key: {}'.format(key))\n",
    "    data_mobility_dict_no_agg['{}'.format(key)] = add_movement_per_cluster(data_dict[key], key, 0)\n",
    "# Save so we don't need to re-run a bunch of times\n",
    "pickle.dump(data_mobility_dict_no_agg, open( \"/Users/kelseydoerksen/Desktop/Giga/SchoolMapping/BWA/Mobility/dict_of_mobility_dfs_no_agg_4clusters.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8777f5c9",
   "metadata": {},
   "source": [
    "# Intersection Analysis ADM1 Clusters\n",
    "Below analysis is for using only the MapBox data for which the school/non-school samples directly overlap the z18 quadkey tile for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72db8863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cluster id to samples\n",
    "sample_df_with_clusters_adm1 = cluster_via_adm(sample_df, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdbf968",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df_with_clusters_adm1 = sample_df_with_clusters_adm1.rename(columns={'shapeName': 'cluster'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9d58be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add mobility data based on intersection\n",
    "# Change crs to EPSG 4326\n",
    "sample_df_with_clusters_adm1 = sample_df_with_clusters_adm1.to_crs('EPSG:4326')\n",
    "\n",
    "mobility_dict = {}\n",
    "months = ['oct','nov','dec','all']\n",
    "for month in months:\n",
    "    mobility_dict[month] = add_movement_data(sample_df_with_clusters_adm1, hourly_movement_df, month, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a28a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-score standardization on all samples\n",
    "for m in mobility_dict.keys():\n",
    "    mobility_dict[m]['z_activity_index_total'] = (mobility_dict[m]['activity_index_total'] - mobility_dict[m]['activity_index_total'].mean()) / mobility_dict[m]['activity_index_total'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcbd615",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_names = sample_df_with_clusters_adm1['cluster'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb75dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run data dict generation\n",
    "data_dict = {}\n",
    "month_dict = {}\n",
    "months = ['oct','nov','dec','all']\n",
    "for month in months:\n",
    "    for name in cluster_names:\n",
    "        weekday = generate_cluster_dict(name, mobility_dict[month], 'weekday')\n",
    "        weekend = generate_cluster_dict(name, mobility_dict[month], 'weekend')\n",
    "        weekday.update(weekend)\n",
    "        data_dict[name] = weekday\n",
    "    pickle.dump(data_dict, open( \"/Users/kelseydoerksen/Desktop/Giga/SchoolMapping/BWA/Mobility/dict_of_unfiltered_mobility_dfs_adm1_{}.p\".format(month), \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9593e565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregating by Mean\n",
    "# Iterate through the months and then load data, then make the aggregation and save\n",
    "dates = ['oct', 'nov', 'dec', 'all']\n",
    "for d in dates:\n",
    "    data = pickle.load(open('/Users/kelseydoerksen/Desktop/Giga/SchoolMapping/BWA/Mobility/dict_of_unfiltered_mobility_dfs_adm1_{}_zscore_norm.p'.format(d), 'rb'))\n",
    "    data_copy = copy.deepcopy(data)\n",
    "    weekday_keys = ['schools_weekday_ai', 'nonschools_weekday_ai', 'clinics_weekday_ai', 'police_weekday_ai', 'farms_weekday_ai', 'urban_schools_weekday_ai', 'rural_schools_weekday_ai', 'urban_nonschools_weekday_ai', 'rural_nonschools_weekday_ai']\n",
    "    weekend_keys = ['schools_weekend_ai', 'nonschools_weekend_ai', 'clinics_weekend_ai', 'police_weekend_ai', 'farms_weekend_ai', 'urban_schools_weekend_ai', 'rural_schools_weekend_ai', 'urban_nonschools_weekend_ai', 'rural_nonschools_weekend_ai']\n",
    "\n",
    "    for cluster_id in data_copy.keys():\n",
    "        for wdkey in weekday_keys:\n",
    "            data_copy[cluster_id][wdkey] = calc_hourly_average_ai(data_copy[cluster_id][wdkey], 0, 'activity_index_total')\n",
    "        for wekey in weekend_keys:\n",
    "            data_copy[cluster_id][wekey] = calc_hourly_average_ai(data_copy[cluster_id][wekey], 1, 'activity_index_total')\n",
    "    \n",
    "    # Pickle the aggregated data\n",
    "    pickle.dump(data_copy, open(\"/Users/kelseydoerksen/Desktop/Giga/SchoolMapping/BWA/Mobility/dict_of_agg_mobility_dfs_adm1_{}.p\".format(d), \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef02ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregating by Median\n",
    "# Iterate through the months and then load data, then make the aggregation and save\n",
    "dates = ['oct', 'nov', 'dec', 'all']\n",
    "for d in dates:\n",
    "    data = pickle.load(open('/Users/kelseydoerksen/Desktop/Giga/SchoolMapping/BWA/Mobility/dict_of_unfiltered_mobility_dfs_adm1_{}_zscore_norm.p'.format(d), 'rb'))\n",
    "    data_copy = copy.deepcopy(data)\n",
    "    weekday_keys = ['schools_weekday_ai', 'nonschools_weekday_ai', 'clinics_weekday_ai', 'police_weekday_ai', 'farms_weekday_ai', 'urban_schools_weekday_ai', 'rural_schools_weekday_ai', 'urban_nonschools_weekday_ai', 'rural_nonschools_weekday_ai']\n",
    "    weekend_keys = ['schools_weekend_ai', 'nonschools_weekend_ai', 'clinics_weekend_ai', 'police_weekend_ai', 'farms_weekend_ai', 'urban_schools_weekend_ai', 'rural_schools_weekend_ai', 'urban_nonschools_weekend_ai', 'rural_nonschools_weekend_ai']\n",
    "\n",
    "    for cluster_id in data_copy.keys():\n",
    "        for wdkey in weekday_keys:\n",
    "            data_copy[cluster_id][wdkey] = calc_hourly_median_ai(data_copy[cluster_id][wdkey], 0, 'activity_index_total')\n",
    "        for wekey in weekend_keys:\n",
    "            data_copy[cluster_id][wekey] = calc_hourly_median_ai(data_copy[cluster_id][wekey], 1, 'activity_index_total')\n",
    "    \n",
    "    # Pickle the aggregated data\n",
    "    pickle.dump(data_copy, open(\"/Users/kelseydoerksen/Desktop/Giga/SchoolMapping/BWA/Mobility/dict_of_agg_median_mobility_dfs_adm1_{}.p\".format(d), \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47d2510",
   "metadata": {},
   "source": [
    "# Intersection Analysis ADM2 Clusters\n",
    "Below analysis is for using only the MapBox data for which the school/non-school samples directly overlap the z18 quadkey tile for"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdad345",
   "metadata": {},
   "source": [
    "#### Old, to update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429f667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cluster dictionaries\n",
    "cluster_names = school_df_with_clusters['shapeName'].unique()\n",
    "data_dict = {}\n",
    "for name in cluster_names:\n",
    "    data_dict['{}'.format(name)] = generate_cluster_dict(name, school_samples_df, nonschool_samples_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d680529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate mobility clusters\n",
    "data_mobility_dict = {}\n",
    "for key in data_dict.keys():\n",
    "    print('Running for key: {}'.format(key))\n",
    "    data_mobility_dict['{}'.format(key)] = generate_hourly_movement_per_cluster(data_dict[key], key, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59faaf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save so we don't need to re-run a bunch of times\n",
    "pickle.dump(data_mobility_dict, open( \"/Users/kelseydoerksen/Desktop/Giga/SchoolMapping/dict_of_mobility_dfs.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f74fb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating mobility clusters without aggregation to down-select several samples\n",
    "# Generate mobility clusters\n",
    "data_mobility_dict_no_agg = {}\n",
    "for key in data_dict.keys():\n",
    "    print('Running for key: {}'.format(key))\n",
    "    data_mobility_dict_no_agg['{}'.format(key)] = add_movement_per_cluster(data_dict[key], key, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890f502b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save so we don't need to re-run a bunch of times\n",
    "pickle.dump(data_mobility_dict_no_agg, open( \"/Users/kelseydoerksen/Desktop/Giga/SchoolMapping/dict_of_mobility_dfs_no_agg.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862745d2",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50290a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading pickled data\n",
    "data_mobility_dict_inter = pickle.load(open(\"/Users/kelseydoerksen/Desktop/Giga/SchoolMapping/BWA/Mobility/dict_of_agg_mobility_dfs_adm1_nov.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac57f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = '/Users/kelseydoerksen/Desktop/Giga/SchoolMapping/BWA/Mobility/Mobility_Analysis_Figs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc87055",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_name = 'South-East District'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291e7d88",
   "metadata": {},
   "source": [
    "## To update below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaa28be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting per cluster for November\n",
    "for cluster_name in list(data_mobility_dict_inter.keys()):\n",
    "    print('Plotting for cluster: {}'.format(cluster_name))\n",
    "    # Plotting weekend activity of schools, nonschools\n",
    "    if data_mobility_dict_inter[cluster_name]['schools_weekend_ai'] is None:\n",
    "        continue\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plot_activity_index(data_mobility_dict_inter[cluster_name][m]['schools_hourly_weekend_ai'], cluster_name, 'Schools Weekend', 'Weekend', m)\n",
    "    plot_activity_index(data_mobility_dict_inter[cluster_name][m]['schools_hourly_weekday_ai'], cluster_name, 'Schools Weekday', 'Weekday', m)\n",
    "    plt.savefig('{}/{}_schools_cluster_{}.png'.format(save_directory, m, cluster_name))\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468d2806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting per cluster per month for Non-Schools\n",
    "months = ['oct', 'nov', 'dec']\n",
    "for cluster_name in list(data_mobility_dict_inter.keys()):\n",
    "    print('Plotting for cluster: {}'.format(cluster_name))\n",
    "    for m in months:\n",
    "        # Plotting weekend activity of schools, nonschools\n",
    "        if data_mobility_dict_inter[cluster_name][m]['nonschools_hourly_weekend_ai'] is None:\n",
    "            continue\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plot_activity_index(data_mobility_dict_inter[cluster_name][m]['nonschools_hourly_weekend_ai'], cluster_name, 'Schools Weekend', 'Weekend', m)\n",
    "        plot_activity_index(data_mobility_dict_inter[cluster_name][m]['nonschools_hourly_weekday_ai'], cluster_name, 'Schools Weekday', 'Weekday', m)\n",
    "        plt.savefig('{}/{}_nonschools_cluster_{}.png'.format(save_directory, m, cluster_name))\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92816c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting per cluster per month for Schools and Non-Schools Weekday\n",
    "months = ['oct', 'nov', 'dec']\n",
    "for cluster_name in list(data_mobility_dict_inter.keys()):\n",
    "    print('Plotting for cluster: {}'.format(cluster_name))\n",
    "    for m in months:\n",
    "        # Plotting weekday activity of schools, nonschools\n",
    "        if data_mobility_dict_inter[cluster_name][m]['schools_hourly_weekday_ai'] is None:\n",
    "            continue\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plot_activity_index(data_mobility_dict_inter[cluster_name][m]['schools_hourly_weekday_ai'], cluster_name, 'Schools Weekday', 'Schools Weekday', m)\n",
    "        plot_activity_index(data_mobility_dict_inter[cluster_name][m]['nonschools_hourly_weekday_ai'], cluster_name, 'NonSchools Weekday', 'NonSchools Weekday', m)\n",
    "        plt.savefig('{}/{}_schools_vs_nonschools_weekday_cluster_{}.png'.format(save_directory, m, cluster_name))\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2d72bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting per cluster per month for Schools and Non-Schools Weekend\n",
    "months = ['oct', 'nov', 'dec']\n",
    "for cluster_name in list(data_mobility_dict_inter.keys()):\n",
    "    print('Plotting for cluster: {}'.format(cluster_name))\n",
    "    for m in months:\n",
    "        # Plotting weekend activity of schools, nonschools\n",
    "        if data_mobility_dict_inter[cluster_name][m]['schools_hourly_weekend_ai'] is None:\n",
    "            continue\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plot_activity_index(data_mobility_dict_inter[cluster_name][m]['schools_hourly_weekend_ai'], cluster_name, 'Schools Weekend', 'Schools Weekend', m)\n",
    "        plot_activity_index(data_mobility_dict_inter[cluster_name][m]['nonschools_hourly_weekend_ai'], cluster_name, 'NonSchools Weekend', 'NonSchools Weekend', m)\n",
    "        plt.savefig('{}/{}_schools_vs_nonschools_weekend_cluster_{}.png'.format(save_directory, m, cluster_name))\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd66d47",
   "metadata": {},
   "source": [
    "# Buffer Analysis\n",
    "\n",
    "1. Define 300m boundary for each school/non-school sample\n",
    "2. Get a list of MapBox quadkey tiles that overlap school/non-school buffer zone\n",
    "3. Take summary statistics of MapBox movement data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e76494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get circle buffer and add to school_df\n",
    "school_df['aeqd_reproj_circle'] = school_df['geometry'].apply(aeqd_reproj_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70504ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add zoom level 18 quadkeys to school dataset\n",
    "school_df['z18_quadkeys'] = school_df.apply(lambda x: generate_quadkeys(x['aeqd_reproj_circle'], 18),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92145ee0",
   "metadata": {},
   "source": [
    "### Subset Non-Schools based on building type\n",
    "We know that our ML models struggle with False Positives on samples represented by hospitals & clinics, police stations and farmsteads. In theory, the activity level around these types of buildings vs schools should be different, so we would like to subset the samples by these categories to observe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2baf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping nans from samples because we can't associate them with building type if not defined\n",
    "school_df_no_nan = nonschool_samples_df.dropna(subset=['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6483ed74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining building types for non-schools (to update to not have to make case sensitive)\n",
    "clinics = ['clinic', 'hospital', 'health', 'medical', 'Clinic', 'Hospital', 'Health', 'Medical']\n",
    "police = ['police', 'Police']\n",
    "farm = ['farm', 'Farm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a243a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_df = filter_df(school_df_no_nan, clinics)\n",
    "police_df = filter_df(school_df_no_nan, police)\n",
    "farm_df = filter_df(school_df_no_nan, farm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77952383",
   "metadata": {},
   "source": [
    "### Subsetting data into Clusters by Administrative Zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c010c472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cluster dictionaries\n",
    "cluster_names = school_df_with_clusters['shapeName'].unique()\n",
    "data_dict = {}\n",
    "for name in cluster_names:\n",
    "    data_dict['{}'.format(name)] = generate_cluster_dict(name, school_samples_df, nonschool_samples_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a174b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate mobility clusters\n",
    "data_mobility_dict = {}\n",
    "for key in data_dict.keys():\n",
    "    print('Running for key: {}'.format(key))\n",
    "    data_mobility_dict['{}'.format(key)] = generate_hourly_movement_per_cluster(data_dict[key], key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8ac5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save so we don't need to re-run a bunch of times\n",
    "pickle.dump(data_mobility_dict, open( \"Users/kdoerksen/dict_of_mobility_dfs_300m_buffer.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327d735c",
   "metadata": {},
   "source": [
    "## Data Visualzation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abc9b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading pickled data\n",
    "data_mobility_dict = pickle.load(open(\"Users/kdoerksen/dict_of_mobility_dfs_300m_buffer.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0223e310",
   "metadata": {},
   "source": [
    "## Category Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec800b04",
   "metadata": {},
   "source": [
    "### Schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57428174",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_samples_df = school_samples_df.reset_index().drop(columns=['index'])\n",
    "school_samples_df_with_movement = add_movement_data(school_samples_df, hourly_movement_df, 'nov')\n",
    "school_samples_hourly_weekday = calc_hourly_average_ai(school_samples_df_with_movement,0)\n",
    "# Plotting\n",
    "plot_activity_index(school_samples_hourly_weekday, 'Schools', 'schools', 'Weekday', marker='off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681631c0",
   "metadata": {},
   "source": [
    "### Non-Schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6625e665",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonschool_samples_df = school_samples_df.reset_index().drop(columns=['index'])\n",
    "nonschool_samples_df_with_movement = add_movement_data(nonschool_samples_df, hourly_movement_df, 'nov')\n",
    "nonschool_samples_hourly_weekday = calc_hourly_average_ai(nonschool_samples_df_with_movement,0)\n",
    "# Plotting\n",
    "plot_activity_index(nonschool_samples_hourly_weekday, 'Non-Schools', 'schools', 'Weekday', marker='off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f4ff82",
   "metadata": {},
   "source": [
    "### Clinics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e092d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_df = clinic_df.reset_index().drop(columns=['index'])\n",
    "clinic_df_with_movement = add_movement_data(clinic_df, hourly_movement_df, 'nov')\n",
    "clinic_df_sum_hourly_weekday = calc_hourly_average_ai(clinic_df_with_movement,0)\n",
    "clinic_df_sum_hourly_weekend = calc_hourly_average_ai(clinic_df_with_movement,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573e3d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plot_activity_index(clinic_df_sum_hourly_weekday, 'Clinic', 'clinic', 'Weekday', marker='on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ed9336",
   "metadata": {},
   "source": [
    "### Police Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa0f345",
   "metadata": {},
   "outputs": [],
   "source": [
    "police_df = police_df.reset_index().drop(columns=['index'])\n",
    "police_df_with_movement = add_movement_data(police_df, hourly_movement_df, 'nov')\n",
    "police_df_sum_hourly_weekday = calc_hourly_average_ai(police_df_with_movement,0)\n",
    "police_df_sum_hourly_weekend = calc_hourly_average_ai(police_df_with_movement,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98528895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plot_activity_index(police_df_sum_hourly_weekday, 'Police', 'police', 'Weekday', marker='on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaf6675",
   "metadata": {},
   "source": [
    "### Farms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fd7e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "farm_df = farm_df.reset_index().drop(columns=['index'])\n",
    "farm_df_with_movement = add_movement_data(farm_df, hourly_movement_df, 'nov')\n",
    "farm_df_sum_hourly_weekday = calc_hourly_average_ai(farm_df_with_movement,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5da5845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plot_activity_index(farm_df_sum_hourly_weekday, 'Farm', 'farm', 'Weekday', marker='on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9493b908",
   "metadata": {},
   "source": [
    "### Schools, Clinics, Police, Farms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8335de0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plot_activity_index(school_samples_hourly_weekday, 'Schools', 'schools', 'Weekday')\n",
    "plot_activity_index(clinic_df_sum_hourly_weekday, 'Clinic', 'clinic', 'Weekday')\n",
    "plot_activity_index(police_df_sum_hourly_weekday, 'Police', 'police', 'Weekday')\n",
    "plot_activity_index(farm_df_sum_hourly_weekday, 'Farm', 'farm', 'Weekday')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d342e4",
   "metadata": {},
   "source": [
    "## Clustered Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9693a906",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "Hard-coding for Southern District, November, can be updated based on what cluster you want to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f299cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_id = 'Southern District'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0c2da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting weekday schools, police, clinics and farms\n",
    "schools_marker_sizes= data_mobility_dict[cluster_id]['nov']['schools_hourly_weekday_ai']['measurements_count']\n",
    "police_marker_sizes= data_mobility_dict[cluster_id]['nov']['police_hourly_weekday_ai']['measurements_count']\n",
    "clinics_marker_sizes= data_mobility_dict[cluster_id]['nov']['clinics_hourly_weekday_ai']['measurements_count']\n",
    "farms_marker_sizes= data_mobility_dict[cluster_id]['nov']['farms_hourly_weekday_ai']['measurements_count']\n",
    "\n",
    "plt. figure(figsize=(10, 6))\n",
    "plot_activity_index(data_mobility_dict[cluster_id]['nov']['schools_hourly_weekday_ai'], cluster_id, 'Schools', 'Weekday')\n",
    "plot_activity_index(data_mobility_dict[cluster_id]['nov']['police_hourly_weekday_ai'], cluster_id, 'Police', 'Weekday')\n",
    "plot_activity_index(data_mobility_dict[cluster_id]['nov']['clinics_hourly_weekday_ai'], cluster_id, 'Clinics', 'Weekday')\n",
    "plot_activity_index(data_mobility_dict[cluster_id]['nov']['farms_hourly_weekday_ai'], cluster_id, 'Farms', 'Weekday')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3230e02a",
   "metadata": {},
   "source": [
    "### Temporal Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1010ab1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plot_activity_index(data_mobility_dict[cluster_id]['oct']['schools_hourly_weekday_ai'], cluster_id, 'Oct Schools', 'Weekday')\n",
    "plot_activity_index(data_mobility_dict[cluster_id]['nov']['schools_hourly_weekday_ai'], cluster_id, 'Nov Schools', 'Weekday')\n",
    "plot_activity_index(data_mobility_dict[cluster_id]['dec']['schools_hourly_weekday_ai'], cluster_id, 'Dec Schools', 'Weekday')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48382eba",
   "metadata": {},
   "source": [
    "## Cluster Comparison Schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2084bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt. figure(figsize=(20, 10))\n",
    "for adm_zone in data_mobility_dict.keys():\n",
    "    plot_activity_index(data_mobility_dict[adm_zone]['oct']['schools_hourly_weekday_ai'], adm_zone, 'Nov Schools', 'Weekday')\n",
    "plt.title('All Cluster School Analaysis November')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b374038c",
   "metadata": {},
   "source": [
    "# Plotting for Tech Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9377799",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/Users/kelseydoerksen/Desktop/Giga/SchoolMapping/BWA/Mobility'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7f9480",
   "metadata": {},
   "source": [
    "# Hourly average Cluster\n",
    "Format for accessing the aggregated data for district is dict[cluster name][schools_weekday_ai] etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb1c5a7",
   "metadata": {},
   "source": [
    "# Sample Selection for MapBox Mobility Presentation\n",
    "Below code is used for the investigative analysis of MapBox mobility data for school and non-school prediction on a sample basis across Botswana. Two clustering methods are used, one clustering based on the Administrative zones level 2, the other clustering based on the elbow method using 4 clusters (representing respectively North, South, East, West part of Botswana)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3ce947",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_5_aois(mobility_dict, cluster_id, target_type):\n",
    "    \"\"\"\n",
    "    Get the top 5 school/non-school (or target)\n",
    "    UIDs ranked by the number of mobility data hits\n",
    "    \n",
    "    :param: mobility_dict: dictionary of mobility data we are filtering\n",
    "    :param: cluster_id: id of the cluster we are querying\n",
    "    :param: target_type: aoi type we are querying, schools, nonschools, weekend, weekday\n",
    "    \"\"\"\n",
    "    return {target_type: dict(mobility_dict[cluster_id][target_type]['UID'].value_counts()[0:5])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0f1ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_top_5_aois(mobility_dict, top_5, cluster_id, time_period, results_dir):\n",
    "    \"\"\"\n",
    "    Plotting the top 5 AOIS per cluster per type\n",
    "    :param: mobility_dict: dict of all mobility data to subset\n",
    "    :param: top_5: dictionary of top 5 aois from number of mobility points\n",
    "    :param: cluster_id: cluster id to subset df\n",
    "    :param: time_period: weekday or weekend analysis\n",
    "    :param: results_dir: directory to save figures to\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Subset dictionary into weekday, weekend schools and non-schools to plot\n",
    "    # Loading all because I have hard-coded the integer order of the data in the list so makes it easier\n",
    "    top_5_schools_weekday = list(top_5[cluster_id][0]['schools_weekday_ai'].keys())\n",
    "    top_5_schools_weekend = list(top_5[cluster_id][1]['schools_weekend_ai'].keys())\n",
    "    top_5_nonschools_weekday = list(top_5[cluster_id][2]['nonschools_weekday_ai'].keys())\n",
    "    top_5_nonschools_weekend = list(top_5[cluster_id][3]['nonschools_weekend_ai'].keys())\n",
    "    \n",
    "    # Now let's subset the mobility_dict of information for the top 5 entries respectively and plot this all\n",
    "    \n",
    "    # Create dfs of subset by time_period\n",
    "    df_schools_weekday_ai = mobility_dict[cluster_id]['schools_weekday_ai']\n",
    "    df_schools_weekend_ai = mobility_dict[cluster_id]['schools_weekend_ai']\n",
    "    df_nonschools_weekday_ai = mobility_dict[cluster_id]['nonschools_weekday_ai']\n",
    "    df_nonschools_weekend_ai = mobility_dict[cluster_id]['nonschools_weekend_ai']\n",
    "    \n",
    "    \n",
    "    # Iterate through the top 5 aois and get their activity data over time\n",
    "    if time_period == 'weekday':\n",
    "        # Save information to list\n",
    "        x_list_schools, y_list_schools, x_list_nonschools, y_list_nonschools = [], [], [], []\n",
    "        for school in top_5_schools_weekday:\n",
    "            df_sorted = df_schools_weekday_ai[df_schools_weekday_ai['UID'] == school].sort_values(by='agg_time_period')\n",
    "            x_list_schools.append(df_sorted['agg_time_period'].to_list())\n",
    "            y_list_schools.append(df_sorted['activity_index_total'].to_list())\n",
    "        for nonschool in top_5_nonschools_weekday:\n",
    "            df_sorted = df_nonschools_weekday_ai[df_nonschools_weekday_ai['UID'] == nonschool].sort_values(by='agg_time_period')\n",
    "            x_list_nonschools.append(df_sorted['agg_time_period'].to_list())\n",
    "            y_list_nonschools.append(df_sorted['activity_index_total'].to_list())\n",
    "            \n",
    "\n",
    "        # Plotting the 5 AOIs for Schools\n",
    "        print('---- Plotting for Schools ----')\n",
    "        num_samples = len(top_5_schools_weekday)\n",
    "        for i in range(num_samples):\n",
    "            plt.plot(x_list_schools[i], y_list_schools[i], label=top_5_schools_weekday[i])\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize='x-small')\n",
    "        plt.xlim(0,23)\n",
    "        plt.ylim(0,1)\n",
    "        plt.xlabel('Hour of Day')\n",
    "        plt.ylabel('Activity Index')\n",
    "        plt.title('Top {} School AOI Activity Index during {} for Cluster {}'.format(num_samples, time_period, cluster_id))\n",
    "        plt.show()\n",
    "        #plt.savefig('{}/school_aoi_top5_{}_{}_cluster_{}.png'.format(results_dir,month, time_period, cluster_id))\n",
    "        plt.close()\n",
    "        \n",
    "        # Plotting the 5 AOIs for NonSchools\n",
    "        print('---- Plotting for NonSchools ----')\n",
    "        num_samples = len(top_5_nonschools_weekday)\n",
    "        for i in range(num_samples):\n",
    "            plt.plot(x_list_nonschools[i], y_list_nonschools[i], label=top_5_nonschools_weekday[i])\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize='x-small')\n",
    "        plt.xlim(0,23)\n",
    "        plt.ylim(0,1)\n",
    "        plt.xlabel('Hour of Day')\n",
    "        plt.ylabel('Activity Index')\n",
    "        plt.title('Top {} NonSchool AOI Activity Index during {} for Cluster {}'.format(num_samples, time_period, cluster_id))\n",
    "        plt.show()\n",
    "        #plt.savefig('{}/nonschool_aoi_top5_{}_cluster_{}.png'.format(results_dir, time_period, cluster_id))\n",
    "        plt.close()\n",
    "    \n",
    "    # Iterate through the top 5 aois and get their activity data over time\n",
    "    if time_period == 'weekend':\n",
    "        # Save information to list\n",
    "        x_list_schools, y_list_schools, x_list_nonschools, y_list_nonschools = [], [], [], []\n",
    "        for school in top_5_schools_weekend:\n",
    "            df_sorted = df_schools_weekend_ai[df_schools_weekend_ai['UID'] == school].sort_values(by='agg_time_period')\n",
    "            x_list_schools.append(df_sorted['agg_time_period'].to_list())\n",
    "            y_list_schools.append(df_sorted['activity_index_total'].to_list())\n",
    "        for nonschool in top_5_nonschools_weekend:\n",
    "            df_sorted = df_nonschools_weekend_ai[df_nonschools_weekend_ai['UID'] == nonschool].sort_values(by='agg_time_period')\n",
    "            x_list_nonschools.append(df_sorted['agg_time_period'].to_list())\n",
    "            y_list_nonschools.append(df_sorted['activity_index_total'].to_list())\n",
    "            \n",
    "        # Plotting the 5 AOIs for Schools\n",
    "        print('---- Plotting for Schools ----')\n",
    "        num_samples = len(top_5_schools_weekend)\n",
    "        for i in range(num_samples):\n",
    "            plt.plot(x_list_schools[i], y_list_schools[i], label=top_5_schools_weekend[i])\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize='x-small')\n",
    "        plt.xlim(0,23)\n",
    "        plt.xlabel('Hour of Day')\n",
    "        plt.ylabel('Activity Index')\n",
    "        plt.title('Top {} School AOI Activity Index during {} for Cluster {}'.format(num_samples, time_period, cluster_id))\n",
    "        plt.show()\n",
    "        #plt.savefig('{}/school_aoi_top5_{}_cluster_{}.png'.format(results_dir, time_period, cluster_id))\n",
    "        plt.close()\n",
    "        \n",
    "        \n",
    "        print('---- Plotting for NonSchools ----')\n",
    "        num_samples = len(top_5_nonschools_weekend)\n",
    "        for i in range(num_samples):\n",
    "            plt.plot(x_list_nonschools[i], y_list_nonschools[i], label=top_5_nonschools_weekend[i])\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize='x-small')\n",
    "        plt.xlim(0,23)\n",
    "        plt.xlabel('Hour of Day')\n",
    "        plt.ylabel('Activity Index')\n",
    "        plt.title('Top {} NonSchool AOI Activity Index during {} for Cluster {}'.format(num_samples, time_period, cluster_id))\n",
    "        #plt.savefig('{}/nonschool_aoi_top5_{}_cluster_{}.png'.format(results_dir, time_period, cluster_id))\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbdca59",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile_dict = pickle.load(open('/Users/kelseydoerksen/Desktop/Giga/SchoolMapping/BWA/Mobility/dict_of_unfiltered_mobility_dfs_adm1_nov_zscore_norm.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fccb66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_se = get_top_5_aois(mobile_dict, 'South-East District', 'schools_weekday_ai')\n",
    "top_5_nw = get_top_5_aois(mobile_dict, 'North-West District', 'schools_weekday_ai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1b608b",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_se['schools_weekday_ai']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d22bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = mobile_dict['South-East District']['schools_weekday_ai']\n",
    "plt.figure(figsize=(10,6))\n",
    "for school in list(top_5_se['schools_weekday_ai'].keys()):\n",
    "    df_sorted = df[df['UID'] == school].sort_values(by='agg_time_period')\n",
    "    norm_vals = minmax_norm(df_sorted[df_sorted['UID'] == school]['activity_index_total'])\n",
    "    plt.plot(df_sorted[df_sorted['UID'] == school]['agg_time_period'], norm_vals, label=school)\n",
    "    plt.xlim(0,23)\n",
    "    plt.xlabel('Hour of Day')\n",
    "    plt.ylabel('Normalized Median Activity Index')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc568e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_nw['schools_weekday_ai']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5908292",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = mobile_dict['North-West District']['schools_weekday_ai']\n",
    "plt.figure(figsize=(10,6))\n",
    "for school in list(top_5_nw['schools_weekday_ai'].keys()):\n",
    "    df_sorted = df[df['UID'] == school].sort_values(by='agg_time_period')\n",
    "    norm_vals = minmax_norm(df_sorted[df_sorted['UID'] == school]['activity_index_total'])\n",
    "    plt.plot(df_sorted[df_sorted['UID'] == school]['agg_time_period'], norm_vals, label=school)\n",
    "    plt.xlim(0,23)\n",
    "    plt.xlabel('Hour of Day')\n",
    "    plt.ylabel('Normalized Median Activity Index')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67feddd",
   "metadata": {},
   "source": [
    "## Administrative Boundaries 1 Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a1f952",
   "metadata": {},
   "source": [
    "### Max-Min Normalized Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7841011",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobility_dict_inter = pickle.load(open(\"{}/MaxMinNormalized/dict_of_mobility_dfs_no_agg.p\".format(root_dir), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d4821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_dict = {}\n",
    "for k in list(mobility_dict_inter.keys()):\n",
    "    top_5_dict[k] = [\n",
    "        get_top_5_aois(mobility_dict_inter, k, 'nov', 'schools_weekday_ai'),\n",
    "        get_top_5_aois(mobility_dict_inter, k, 'nov', 'schools_weekend_ai'),\n",
    "        get_top_5_aois(mobility_dict_inter, k, 'nov', 'nonschools_weekday_ai'),\n",
    "        get_top_5_aois(mobility_dict_inter, k, 'nov', 'nonschools_weekend_ai'),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7cb6da",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "save_directory = '/Users/kelseydoerksen/Desktop/Giga/SchoolMapping/BWA/Mobility/Mobility_Analysis_Figs'\n",
    "\n",
    "for cluster in list(mobility_dict_inter.keys()):\n",
    "    print('Running for cluster: {}'.format(cluster))\n",
    "    plotting_top_5_aois(mobility_dict_inter, top_5_dict, cluster, 'nov', 'weekday', save_directory)\n",
    "    plotting_top_5_aois(mobility_dict_inter, top_5_dict, cluster, 'nov', 'weekend', save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56fdfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobility_dict_inter = pickle.load(open(\"{}/MaxMinNormalized/dict_of_mobility_dfs.p\".format(root_dir), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c09a6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# South-East District Nov\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.xlim(0,23)\n",
    "plt.ylim(0,1)\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Activity Index')\n",
    "plt.plot(mobility_dict_inter['South-East District']['nov']['schools_hourly_weekday_ai']['activity_index_total'], label='Weekday', color='green')\n",
    "plt.plot(mobility_dict_inter['South-East District']['nov']['schools_hourly_weekend_ai']['activity_index_total'], label='Weekend', color='magenta')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669e5f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# North-West District Nov\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.xlim(0,23)\n",
    "plt.ylim(0,1)\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Activity Index')\n",
    "plt.plot(mobility_dict_inter['North-West District']['nov']['schools_hourly_weekday_ai']['activity_index_total'], label='Weekday', color='green')\n",
    "plt.plot(mobility_dict_inter['North-West District']['nov']['schools_hourly_weekend_ai']['activity_index_total'], label='Weekend', color='magenta')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c051231d",
   "metadata": {},
   "source": [
    "## Raw output median aggregation\n",
    "Using median instead of mean aggregation, plotting the data for the ppt, hard coding first for Nov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39338ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nov_mobility_dict_inter_med = pickle.load(open(\"/Users/kelseydoerksen/Desktop/Giga/SchoolMapping/BWA/Mobility/dict_of_agg_median_mobility_dfs_adm1_nov.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b308be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "oct_mobility_dict_inter_med = pickle.load(open(\"/Users/kelseydoerksen/Desktop/Giga/SchoolMapping/BWA/Mobility/dict_of_agg_median_mobility_dfs_adm1_oct.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926337dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_mobility_dict_inter_med = pickle.load(open(\"/Users/kelseydoerksen/Desktop/Giga/SchoolMapping/BWA/Mobility/dict_of_agg_median_mobility_dfs_adm1_dec.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006ad389",
   "metadata": {},
   "outputs": [],
   "source": [
    "month = 'dec'\n",
    "mobility_dict_inter_med = dec_mobility_dict_inter_med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42505f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_norm(df):\n",
    "    normalized_df=(df-df.min())/(df.max()-df.min())\n",
    "    return normalized_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafa8da2",
   "metadata": {},
   "source": [
    "### South-East"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3dd9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# South-East District\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.xlim(0,23)\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Normalized Median Activity Index')\n",
    "plt.plot(minmax_norm(mobility_dict_inter_med['South-East District']['schools_weekday_ai']), label='Schools')\n",
    "plt.plot(minmax_norm(mobility_dict_inter_med['South-East District']['nonschools_weekday_ai']), label='Non-Schools')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd53eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.xlim(0,23)\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Normalized Median Activity Index')\n",
    "plt.plot(minmax_norm(mobility_dict_inter_med['South-East District']['schools_weekday_ai']), label='Weekday', color='green')\n",
    "plt.plot(minmax_norm(mobility_dict_inter_med['South-East District']['schools_weekend_ai']), label='Weekend', color='magenta')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57f97a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.xlim(0,23)\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Normalized Median Activity Index')\n",
    "plt.plot(minmax_norm(mobility_dict_inter_med['South-East District']['nonschools_weekday_ai']), label='Weekday', color='green')\n",
    "plt.plot(minmax_norm(mobility_dict_inter_med['South-East District']['nonschools_weekend_ai']), label='Weekend', color='magenta')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f97d5ab",
   "metadata": {},
   "source": [
    "## North-West"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a349aa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# North-West District Nov\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.xlim(0,23)\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Normalized Median Activity Index')\n",
    "plt.plot(minmax_norm(mobility_dict_inter_med['North-West District']['schools_weekday_ai']), label='Schools')\n",
    "plt.plot(minmax_norm(mobility_dict_inter_med['North-West District']['nonschools_weekday_ai']), label='Non-Schools')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1367695d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# North-West District Nov\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.xlim(0,23)\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Normalized Median Activity Index')\n",
    "plt.plot(minmax_norm(mobility_dict_inter_med['North-West District']['schools_weekday_ai']), label='Weekday', color=\"green\")\n",
    "plt.plot(minmax_norm(mobility_dict_inter_med['North-West District']['schools_weekend_ai']), label='Weekend', color=\"magenta\")\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befc309f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# North-West District Nov\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.xlim(0,23)\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Normalized Median Activity Index')\n",
    "plt.plot(minmax_norm(mobility_dict_inter_med['North-West District']['nonschools_weekday_ai']), label='Weekday', color=\"green\")\n",
    "plt.plot(minmax_norm(mobility_dict_inter_med['North-West District']['nonschools_weekend_ai']), label='Weekend', color=\"magenta\")\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488f8a9c",
   "metadata": {},
   "source": [
    "## 4 Cluster Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593017f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobility_dict_4clusters = pickle.load(open(\"{}/MaxMinNormalized/dict_of_mobility_dfs_no_agg_4clusters.p\".format(root_dir), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889805f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_dict_4_clusters = {}\n",
    "for k in list(mobility_dict_4clusters.keys()):\n",
    "    top_5_dict[k] = [\n",
    "        get_top_5_aois(mobility_dict_4clusters, k, 'nov', 'schools_weekday_ai'),\n",
    "        get_top_5_aois(mobility_dict_4clusters, k, 'nov', 'schools_weekend_ai'),\n",
    "        get_top_5_aois(mobility_dict_4clusters, k, 'nov', 'nonschools_weekday_ai'),\n",
    "        get_top_5_aois(mobility_dict_4clusters, k, 'nov', 'nonschools_weekend_ai'),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6653e36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = '/Users/kelseydoerksen/Desktop/Giga/SchoolMapping/BWA/Mobility/Mobility_Analysis_Figs'\n",
    "\n",
    "for cluster in list(mobility_dict_4clusters.keys()):\n",
    "    print('Running for cluster: {}'.format(cluster))\n",
    "    plotting_top_5_aois(mobility_dict_4clusters, top_5_dict, cluster, 'nov', 'weekday', save_directory)\n",
    "    plotting_top_5_aois(mobility_dict_4clusters, top_5_dict, cluster, 'nov', 'weekend', save_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35547181",
   "metadata": {},
   "source": [
    "# Extracting Features for ML model\n",
    "Extracting features from the time series data to be used as features for the school/non-school prediction task. This should be per-sample that has mobility data; if we do this on a cluster-level, the model will be \"cheating\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1233253",
   "metadata": {},
   "source": [
    "### Old -> Cluster-level extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0b2c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_timeseries_features(df_subset):\n",
    "    \"\"\"\n",
    "    Function to generate time series features\n",
    "    from the mobility data to use in the ML model\n",
    "    Feature space\n",
    "    \n",
    "    :param: df_subset: subset df of cluster we are interested in\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # Check for schools\n",
    "    \n",
    "    if df_subset['schools_weekday_ai'] is None:\n",
    "        features['schools_weekday_var'] = np.nan\n",
    "        features['schools_weekday_max'] = np.nan\n",
    "    else:\n",
    "        features['schools_weekday_var'] = df_subset['schools_weekday_ai'].var()\n",
    "        features['schools_weekday_max'] = df_subset['schools_weekday_ai'].idxmax()\n",
    "        \n",
    "    if df_subset['schools_weekend_ai'] is None:\n",
    "        features['schools_weekend_var'] = np.nan\n",
    "        features['schools_weekend_max'] = np.nan\n",
    "    else:\n",
    "        features['schools_weekend_var'] = df_subset['schools_weekend_ai'].var()\n",
    "        features['schools_weekend_max'] = df_subset['schools_weekend_ai'].idxmax()\n",
    "        \n",
    "    # Check for non-schools\n",
    "    if df_subset['nonschools_weekday_ai'] is None:\n",
    "        features['nonschools_weekday_var'] = np.nan\n",
    "        features['nonschools_weekday_max'] = np.nan\n",
    "    else:\n",
    "        features['nonschools_weekday_var'] = df_subset['nonschools_weekday_ai'].var()\n",
    "        features['nonschools_weekday_max'] = df_subset['nonschools_weekday_ai'].idxmax()\n",
    "        \n",
    "    if df_subset['nonschools_weekend_ai'] is None:\n",
    "        features['nonschools_weekend_var'] = np.nan\n",
    "        features['nonschools_weekend_max'] = np.nan\n",
    "    else:\n",
    "        features['nonschools_weekend_var'] = df_subset['nonschools_weekend_ai'].var()\n",
    "        features['nonschools_weekend_max'] = df_subset['nonschools_weekend_ai'].idxmax()\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527bbadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "adm1_data_med = pickle.load(open('/Users/kelseydoerksen/Desktop/Giga/SchoolMapping/BWA/Mobility/dict_of_agg_median_mobility_dfs_adm1_nov.p', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1623120",
   "metadata": {},
   "outputs": [],
   "source": [
    "adm1_data_mean = pickle.load(open('/Users/kelseydoerksen/Desktop/Giga/SchoolMapping/BWA/Mobility/dict_of_agg_mobility_dfs_adm1_nov.p', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf97f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dict = {}\n",
    "cluster_names = list(adm1_data_med.keys())\n",
    "for c in cluster_names:\n",
    "    features = generate_timeseries_features(adm1_data[c])\n",
    "    feature_dict['{}_features'.format(c)] = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22755fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in samples df, add clusters and then add feature info\n",
    "# Loading BWA school geojson data\n",
    "BWA_samples = gpd.read_file('/Users/kelseydoerksen/Desktop/Giga/SchoolMapping/BWA/BWA_train.geojson')\n",
    "# Add cluster id to samples\n",
    "BWA_samples_clustered = cluster_via_adm(BWA_samples, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e0018e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features_per_cluster(aoi_sample_df, feature_dictionary):\n",
    "    \"\"\"\n",
    "    Create a df of features for the cluster, uid specified\n",
    "    :param: sample_df: df of samples to get ordered UID from\n",
    "    :param: feature_dictionary: dictionary of features previously generated\n",
    "    \"\"\"\n",
    "    aoi_sample_df = aoi_sample_df.sort_values(by='UID')\n",
    "    UID_ordered = aoi_sample_df['UID'].to_list()\n",
    "    cluster_names_ordered = aoi_sample_df['shapeName'].to_list()\n",
    "    features_to_add = {\n",
    "        'schools_weekday_var': [],\n",
    "        'schools_weekend_var': [],\n",
    "        'nonschools_weekday_var': [],\n",
    "        'nonschools_weekend_var': [],\n",
    "        'schools_weekday_max': [],\n",
    "        'schools_weekend_max': [],\n",
    "        'nonschools_weekday_max': [],\n",
    "        'nonschools_weekend_max': [],\n",
    "    }\n",
    "    for i in range(len(UID_ordered)):\n",
    "        features_to_add['schools_weekday_var'].append(feature_dictionary['{}_features'.format(cluster_names_ordered[i])]['schools_weekday_var'])\n",
    "        features_to_add['schools_weekend_var'].append(feature_dictionary['{}_features'.format(cluster_names_ordered[i])]['schools_weekend_var'])\n",
    "        features_to_add['nonschools_weekday_var'].append(feature_dictionary['{}_features'.format(cluster_names_ordered[i])]['nonschools_weekday_var'])\n",
    "        features_to_add['nonschools_weekend_var'].append(feature_dictionary['{}_features'.format(cluster_names_ordered[i])]['nonschools_weekend_var'])\n",
    "        features_to_add['schools_weekday_max'].append(feature_dictionary['{}_features'.format(cluster_names_ordered[i])]['schools_weekday_max'])\n",
    "        features_to_add['schools_weekend_max'].append(feature_dictionary['{}_features'.format(cluster_names_ordered[i])]['schools_weekend_max'])\n",
    "        features_to_add['nonschools_weekday_max'].append(feature_dictionary['{}_features'.format(cluster_names_ordered[i])]['nonschools_weekday_max'])\n",
    "        features_to_add['nonschools_weekend_max'].append(feature_dictionary['{}_features'.format(cluster_names_ordered[i])]['nonschools_weekend_max'])\n",
    "        \n",
    "    \n",
    "    df = pd.DataFrame.from_dict(features_to_add)\n",
    "    df['UID'] = UID_ordered\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248ebe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feats = add_features_per_cluster(BWA_samples_clustered, feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69912d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding to engineered features\n",
    "# Load pre-processed features\n",
    "training_df = pd.read_csv('/Users/kelseydoerksen/Desktop/Giga/SchoolMapping/BWA/1000m_buffer/TrainingData_uncorrelated.csv')\n",
    "testing_df = pd.read_csv('/Users/kelseydoerksen/Desktop/Giga/SchoolMapping/BWA/1000m_buffer/TestingData_uncorrelated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05184f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mobility_features(query_df, mobile_feat_df):\n",
    "    \"\"\"\n",
    "    Add mobility features, subsetting into class, adding features then combining\n",
    "    :param: query_df: original df to add feature to\n",
    "    :pararm: mobile_feat_df: df of mobile features\n",
    "    \"\"\"\n",
    "    \n",
    "    school_class = query_df[query_df['class'] == 1]\n",
    "    nonschool_class = query_df[query_df['class'] == 0]\n",
    "    \n",
    "    mobile_feats_school = mobile_feat_df[mobile_feat_df['UID'].isin(school_class['UID'].to_list())]\n",
    "    mobile_feats_nonschool = mobile_feat_df[mobile_feat_df['UID'].isin(nonschool_class['UID'].to_list())]\n",
    "    \n",
    "    combined_schools = pd.merge(school_class, mobile_feats_school, on='UID')\n",
    "    # Drop non-school columns\n",
    "    combined_schools = combined_schools.drop(columns=['nonschools_weekday_var', 'nonschools_weekend_var',\n",
    "                                                     'nonschools_weekday_max', 'nonschools_weekend_max'])\n",
    "    # Rename school columns\n",
    "    combined_schools = combined_schools.rename(columns={'schools_weekday_var': 'weekday_var', 'schools_weekend_var': 'weekend_var',\n",
    "                                    'schools_weekday_max': 'weekday_max', 'schools_weekend_max': 'weekend_max'})\n",
    "    \n",
    "    \n",
    "    combined_nonschools = pd.merge(nonschool_class, mobile_feats_nonschool, on='UID')\n",
    "    combined_nonschools = combined_nonschools.drop(columns=['schools_weekday_var', 'schools_weekend_var',\n",
    "                                                     'schools_weekday_max', 'schools_weekend_max'])\n",
    "    combined_nonschools = combined_nonschools.rename(columns={'nonschools_weekday_var': 'weekday_var', 'nonschools_weekend_var': 'weekend_var',\n",
    "                                    'nonschools_weekday_max': 'weekday_max', 'nonschools_weekend_max': 'weekend_max'})\n",
    "                               \n",
    "    total_combined = pd.concat([combined_schools,combined_nonschools], ignore_index=True)\n",
    "    \n",
    "    return total_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6091ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_combine = add_mobility_features(training_df, df_feats)\n",
    "test_combine = add_mobility_features(testing_df, df_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a4ec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_combine.to_csv('/Users/kelseydoerksen/Desktop/Giga/SchoolMapping/BWA/1000m_buffer/TrainingData_uncorrelated_added_mobility.csv')\n",
    "test_combine.to_csv('/Users/kelseydoerksen/Desktop/Giga/SchoolMapping/BWA/1000m_buffer/TestingData_uncorrelated_added_mobility.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f68a56",
   "metadata": {},
   "source": [
    "## Adding mobility data per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7c1964d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mobility dict and make dataframe\n",
    "mobile_dict_feats = pickle.load(open('/Users/kelseydoerksen/Desktop/Giga/SchoolMapping/BWA/Mobility/dict_of_mobility_features_nov.p', 'rb'))\n",
    "mobile_feats_df = pd.DataFrame(mobile_dict_feats)\n",
    "mobile_feats_df = mobile_feats_df.rename(columns={'uid': 'UID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1c50e0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train, test data\n",
    "training_df = pd.read_csv('/Users/kelseydoerksen/Desktop/Giga/SchoolMapping/BWA/1000m_buffer/TrainingData_uncorrelated.csv')\n",
    "testing_df = pd.read_csv('/Users/kelseydoerksen/Desktop/Giga/SchoolMapping/BWA/1000m_buffer/TestingData_uncorrelated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "125edf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine dataframes\n",
    "training_df_with_mobility = pd.merge(training_df, mobile_feats_df, on='UID')\n",
    "testing_df_with_mobility = pd.merge(testing_df, mobile_feats_df, on='UID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "129b84d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the weekend columns\n",
    "training_df_with_mobility = training_df_with_mobility.drop(columns=['weekend_var','weekend_peak_hour', 'weekend_measurement_count'])\n",
    "testing_df_with_mobility = testing_df_with_mobility.drop(columns=['weekend_var','weekend_peak_hour', 'weekend_measurement_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cf71709a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nans\n",
    "training_df_with_mobility = training_df_with_mobility.dropna()\n",
    "testing_df_with_mobility = testing_df_with_mobility.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb78d0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving downsampled mobile to directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e351de34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save mobile + geo to directory\n",
    "training_df_with_mobility.to_csv('/Users/kelseydoerksen/Desktop/Giga/SchoolMapping/BWA/1000m_buffer/TrainingData_uncorrelated_added_mobility.csv')\n",
    "testing_df_with_mobility.to_csv('/Users/kelseydoerksen/Desktop/Giga/SchoolMapping/BWA/1000m_buffer/TestingData_uncorrelated_added_mobility.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
